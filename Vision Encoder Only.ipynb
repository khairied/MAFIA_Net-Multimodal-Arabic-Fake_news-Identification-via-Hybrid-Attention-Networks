{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11118864,"sourceType":"datasetVersion","datasetId":6933281}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport timm\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, Subset\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom torchvision.datasets import ImageFolder\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nimport random\nimport warnings\n##from tqdm import tqdm \nwarnings.filterwarnings(\"ignore\")\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    ##torch.backends.cudnn.deterministic = False\n    ##torch.backends.cudnn.benchmark = True\n    torch.use_deterministic_algorithms(True, warn_only=True)\n    print(f\"[INFO] All seeds set to {seed}\")\n\nseed_everything(42)\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(42)\n\n# Configuration\n##DATA_DIR = \"/kaggle/input/mapsimgtxt/spammultimodal\"  # Update with dataset path\nDATA_DIR = \"/kaggle/input/ekafnewsforkhawla/sorted_imagesOur\" \n\nBATCH_SIZE = 8\nEPOCHS = 3\nLR = 2e-5\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define models with specific input sizes      \nMODELS = {\"vit_base_patch32_224\": (224, 224),    \n          \"deit_tiny_patch16_224.fb_in1k\": (224, 224),    \n          \"beit_base_patch16_224.in22k_ft_in22k\": (224, 224),    \n          \"cait_xxs24_224.fb_dist_in1k\": (224, 224),\n          \"timm/crossvit_18_dagger_408.in1k\": (408, 408)\n}\n\n# Load dataset\ndataset = ImageFolder(DATA_DIR)\nnum_classes = len(dataset.classes)\nlabels = [sample[1] for sample in dataset.samples]  # Extract labels properly\nkf = StratifiedKFold(n_splits=5, shuffle=False, random_state=None)\n\ndef free_gpu_memory():\n    torch.cuda.empty_cache()\n    torch.cuda.ipc_collect()\n\ndef train_model(model_name, input_size):\n    print(f\"Training {model_name}...\")\n    \n    # Free GPU memory before starting a new model\n    \n    \n    # Define data transformations\n    transform = transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.ToTensor()\n    ])\n    dataset.transform = transform  # Apply transformation to dataset\n    \n        \n    all_preds1, all_labels1 = [], []  # Accumulate results across folds\n    \n    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset.samples, dataset.targets)):\n        free_gpu_memory()\n        model = timm.create_model(model_name, pretrained=True, num_classes=num_classes).to(DEVICE)\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=LR)\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)        \n        print(f\"Fold {fold+1}/5\")\n        train_subsampler = Subset(dataset, train_idx)\n        val_subsampler = Subset(dataset, val_idx)\n        \n        train_loader = DataLoader(train_subsampler, batch_size=BATCH_SIZE,generator=g, shuffle=True)\n        val_loader = DataLoader(val_subsampler, batch_size=BATCH_SIZE, generator=g,shuffle=False)\n        \n        for epoch in range(EPOCHS):\n            model.train()\n            running_loss, correct, total = 0.0, 0, 0\n            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n            \n            for images, labels in progress_bar:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                optimizer.zero_grad()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n                running_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n                progress_bar.set_postfix(loss=running_loss / len(train_loader), acc=100 * correct / total)\n            \n            print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n            scheduler.step(running_loss / len(train_loader))\n        \n        # Validation\n        model.eval()\n        all_preds, all_labels = [], []\n        with torch.no_grad():\n            for images, labels in tqdm(val_loader, desc=\"Validating\", leave=False):\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = model(images)\n                _, preds = torch.max(outputs, 1)\n                all_preds.extend(preds.cpu().numpy())\n                all_labels.extend(labels.cpu().numpy())\n                all_preds1.extend(preds.cpu().numpy())\n                all_labels1.extend(labels.cpu().numpy())\n            \n        print(f\"Fold {fold+1} Accuracy: {accuracy_score(all_labels, all_preds):.4f}\")\n        print(classification_report(all_labels, all_preds, digits=4, zero_division=0))  \n        print(confusion_matrix(all_labels, all_preds))\n    \n    print(f\"\\n✅✅✅✅✅✅✅✅✅✅✅ {model_name}✅✅✅✅✅✅✅✅✅✅✅✅✅\")\n    print(classification_report(all_labels1, all_preds1, digits=4, zero_division=0))  \n    print(confusion_matrix(all_labels1, all_preds1))\n    print(f\"\\n✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅\")\n\n# Train each model with corresponding input size\nfor model_name, input_size in MODELS.items():\n    train_model(model_name, input_size)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-01T21:44:27.386084Z","iopub.execute_input":"2026-02-01T21:44:27.386487Z","iopub.status.idle":"2026-02-02T00:53:37.444528Z","shell.execute_reply.started":"2026-02-01T21:44:27.386459Z","shell.execute_reply":"2026-02-02T00:53:37.443682Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[INFO] All seeds set to 42\nTraining vit_base_patch32_224...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33a3ad07a4c140d5aac7a0fee639cd94"}},"metadata":{}},{"name":"stdout","text":"Fold 1/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5391, Accuracy: 74.40%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3506, Accuracy: 85.18%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.1046, Accuracy: 96.35%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 1 Accuracy: 0.6936\n              precision    recall  f1-score   support\n\n           0     0.4393    0.5568    0.4911       273\n           1     0.8226    0.7430    0.7808       755\n\n    accuracy                         0.6936      1028\n   macro avg     0.6309    0.6499    0.6360      1028\nweighted avg     0.7208    0.6936    0.7039      1028\n\n[[152 121]\n [194 561]]\nFold 2/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5171, Accuracy: 76.06%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.2565, Accuracy: 89.54%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.0617, Accuracy: 98.18%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 2 Accuracy: 0.6839\n              precision    recall  f1-score   support\n\n           0     0.3863    0.3309    0.3564       272\n           1     0.7711    0.8108    0.7905       756\n\n    accuracy                         0.6839      1028\n   macro avg     0.5787    0.5709    0.5734      1028\nweighted avg     0.6693    0.6839    0.6756      1028\n\n[[ 90 182]\n [143 613]]\nFold 3/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5126, Accuracy: 76.20%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.2411, Accuracy: 90.05%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.0553, Accuracy: 98.52%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 3 Accuracy: 0.7383\n              precision    recall  f1-score   support\n\n           0     0.5319    0.0919    0.1567       272\n           1     0.7482    0.9709    0.8451       756\n\n    accuracy                         0.7383      1028\n   macro avg     0.6401    0.5314    0.5009      1028\nweighted avg     0.6910    0.7383    0.6630      1028\n\n[[ 25 247]\n [ 22 734]]\nFold 4/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5114, Accuracy: 76.82%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.2481, Accuracy: 89.61%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.0675, Accuracy: 98.10%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 4 Accuracy: 0.7020\n              precision    recall  f1-score   support\n\n           0     0.3910    0.2243    0.2850       272\n           1     0.7577    0.8742    0.8118       755\n\n    accuracy                         0.7020      1027\n   macro avg     0.5744    0.5492    0.5484      1027\nweighted avg     0.6606    0.7020    0.6723      1027\n\n[[ 61 211]\n [ 95 660]]\nFold 5/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5152, Accuracy: 76.21%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.2657, Accuracy: 89.30%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.0706, Accuracy: 98.22%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 5 Accuracy: 0.7196\n              precision    recall  f1-score   support\n\n           0     0.3824    0.0956    0.1529       272\n           1     0.7435    0.9444    0.8320       755\n\n    accuracy                         0.7196      1027\n   macro avg     0.5629    0.5200    0.4925      1027\nweighted avg     0.6478    0.7196    0.6521      1027\n\n[[ 26 246]\n [ 42 713]]\n\n✅✅✅✅✅✅✅✅✅✅✅ vit_base_patch32_224✅✅✅✅✅✅✅✅✅✅✅✅✅\n              precision    recall  f1-score   support\n\n           0     0.4165    0.2601    0.3202      1361\n           1     0.7652    0.8687    0.8136      3777\n\n    accuracy                         0.7075      5138\n   macro avg     0.5908    0.5644    0.5669      5138\nweighted avg     0.6728    0.7075    0.6829      5138\n\n[[ 354 1007]\n [ 496 3281]]\n\n✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅\nTraining deit_tiny_patch16_224.fb_in1k...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/22.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09e38e68e815463490dc6f343f3dfae7"}},"metadata":{}},{"name":"stdout","text":"Fold 1/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5474, Accuracy: 74.45%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.4201, Accuracy: 81.27%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.2210, Accuracy: 92.26%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 1 Accuracy: 0.6877\n              precision    recall  f1-score   support\n\n           0     0.4000    0.3516    0.3743       273\n           1     0.7754    0.8093    0.7920       755\n\n    accuracy                         0.6877      1028\n   macro avg     0.5877    0.5805    0.5831      1028\nweighted avg     0.6757    0.6877    0.6810      1028\n\n[[ 96 177]\n [144 611]]\nFold 2/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5383, Accuracy: 74.33%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3825, Accuracy: 82.51%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.1913, Accuracy: 93.38%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 2 Accuracy: 0.6761\n              precision    recall  f1-score   support\n\n           0     0.3467    0.2537    0.2930       272\n           1     0.7551    0.8280    0.7899       756\n\n    accuracy                         0.6761      1028\n   macro avg     0.5509    0.5409    0.5414      1028\nweighted avg     0.6471    0.6761    0.6584      1028\n\n[[ 69 203]\n [130 626]]\nFold 3/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5317, Accuracy: 75.16%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3666, Accuracy: 83.48%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.1778, Accuracy: 93.80%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 3 Accuracy: 0.7082\n              precision    recall  f1-score   support\n\n           0     0.3814    0.1654    0.2308       272\n           1     0.7505    0.9034    0.8199       756\n\n    accuracy                         0.7082      1028\n   macro avg     0.5660    0.5344    0.5253      1028\nweighted avg     0.6529    0.7082    0.6640      1028\n\n[[ 45 227]\n [ 73 683]]\nFold 4/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5303, Accuracy: 75.14%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3650, Accuracy: 84.68%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.1665, Accuracy: 95.14%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 4 Accuracy: 0.6806\n              precision    recall  f1-score   support\n\n           0     0.3272    0.1949    0.2442       272\n           1     0.7468    0.8556    0.7975       755\n\n    accuracy                         0.6806      1027\n   macro avg     0.5370    0.5252    0.5209      1027\nweighted avg     0.6357    0.6806    0.6510      1027\n\n[[ 53 219]\n [109 646]]\nFold 5/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5362, Accuracy: 74.95%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.4041, Accuracy: 82.92%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.2067, Accuracy: 92.61%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 5 Accuracy: 0.7089\n              precision    recall  f1-score   support\n\n           0     0.4151    0.2426    0.3063       272\n           1     0.7627    0.8768    0.8158       755\n\n    accuracy                         0.7089      1027\n   macro avg     0.5889    0.5597    0.5610      1027\nweighted avg     0.6706    0.7089    0.6808      1027\n\n[[ 66 206]\n [ 93 662]]\n\n✅✅✅✅✅✅✅✅✅✅✅ deit_tiny_patch16_224.fb_in1k✅✅✅✅✅✅✅✅✅✅✅✅✅\n              precision    recall  f1-score   support\n\n           0     0.3747    0.2417    0.2939      1361\n           1     0.7577    0.8546    0.8033      3777\n\n    accuracy                         0.6923      5138\n   macro avg     0.5662    0.5482    0.5486      5138\nweighted avg     0.6563    0.6923    0.6683      5138\n\n[[ 329 1032]\n [ 549 3228]]\n\n✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅\nTraining beit_base_patch16_224.in22k_ft_in22k...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/414M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75bd97a01e314755b0d930657d94536e"}},"metadata":{}},{"name":"stdout","text":"Fold 1/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5849, Accuracy: 73.45%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.5795, Accuracy: 73.53%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.5533, Accuracy: 74.48%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 1 Accuracy: 0.7335\n              precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000       273\n           1     0.7342    0.9987    0.8462       755\n\n    accuracy                         0.7335      1028\n   macro avg     0.3671    0.4993    0.4231      1028\nweighted avg     0.5392    0.7335    0.6215      1028\n\n[[  0 273]\n [  1 754]]\nFold 2/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5734, Accuracy: 73.58%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.4638, Accuracy: 78.59%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.2592, Accuracy: 89.83%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 2 Accuracy: 0.6459\n              precision    recall  f1-score   support\n\n           0     0.3403    0.3603    0.3500       272\n           1     0.7649    0.7487    0.7567       756\n\n    accuracy                         0.6459      1028\n   macro avg     0.5526    0.5545    0.5533      1028\nweighted avg     0.6525    0.6459    0.6491      1028\n\n[[ 98 174]\n [190 566]]\nFold 3/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5781, Accuracy: 73.50%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.4826, Accuracy: 77.54%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.3035, Accuracy: 87.64%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 3 Accuracy: 0.7130\n              precision    recall  f1-score   support\n\n           0     0.2909    0.0588    0.0979       272\n           1     0.7369    0.9484    0.8294       756\n\n    accuracy                         0.7130      1028\n   macro avg     0.5139    0.5036    0.4636      1028\nweighted avg     0.6189    0.7130    0.6358      1028\n\n[[ 16 256]\n [ 39 717]]\nFold 4/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5674, Accuracy: 73.63%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.4536, Accuracy: 78.96%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.2436, Accuracy: 90.68%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 4 Accuracy: 0.7176\n              precision    recall  f1-score   support\n\n           0     0.4274    0.1949    0.2677       272\n           1     0.7575    0.9060    0.8251       755\n\n    accuracy                         0.7176      1027\n   macro avg     0.5924    0.5504    0.5464      1027\nweighted avg     0.6701    0.7176    0.6775      1027\n\n[[ 53 219]\n [ 71 684]]\nFold 5/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5818, Accuracy: 73.51%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.5329, Accuracy: 75.58%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.3992, Accuracy: 82.90%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 5 Accuracy: 0.6738\n              precision    recall  f1-score   support\n\n           0     0.2797    0.1471    0.1928       272\n           1     0.7376    0.8636    0.7956       755\n\n    accuracy                         0.6738      1027\n   macro avg     0.5086    0.5053    0.4942      1027\nweighted avg     0.6163    0.6738    0.6359      1027\n\n[[ 40 232]\n [103 652]]\n\n✅✅✅✅✅✅✅✅✅✅✅ beit_base_patch16_224.in22k_ft_in22k✅✅✅✅✅✅✅✅✅✅✅✅✅\n              precision    recall  f1-score   support\n\n           0     0.3388    0.1521    0.2099      1361\n           1     0.7451    0.8930    0.8124      3777\n\n    accuracy                         0.6968      5138\n   macro avg     0.5419    0.5226    0.5112      5138\nweighted avg     0.6375    0.6968    0.6528      5138\n\n[[ 207 1154]\n [ 404 3373]]\n\n✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅\nTraining cait_xxs24_224.fb_dist_in1k...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/47.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8e473ee56924525b357aef2da7c716a"}},"metadata":{}},{"name":"stdout","text":"Fold 1/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5563, Accuracy: 74.21%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3900, Accuracy: 82.43%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.1830, Accuracy: 93.53%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 1 Accuracy: 0.6907\n              precision    recall  f1-score   support\n\n           0     0.3636    0.2198    0.2740       273\n           1     0.7532    0.8609    0.8035       755\n\n    accuracy                         0.6907      1028\n   macro avg     0.5584    0.5404    0.5387      1028\nweighted avg     0.6497    0.6907    0.6628      1028\n\n[[ 60 213]\n [105 650]]\nFold 2/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5438, Accuracy: 74.77%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3751, Accuracy: 83.36%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.1741, Accuracy: 94.31%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 2 Accuracy: 0.6702\n              precision    recall  f1-score   support\n\n           0     0.3169    0.2132    0.2549       272\n           1     0.7467    0.8347    0.7883       756\n\n    accuracy                         0.6702      1028\n   macro avg     0.5318    0.5239    0.5216      1028\nweighted avg     0.6330    0.6702    0.6471      1028\n\n[[ 58 214]\n [125 631]]\nFold 3/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5334, Accuracy: 75.11%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3692, Accuracy: 83.63%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.1566, Accuracy: 94.74%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 3 Accuracy: 0.7160\n              precision    recall  f1-score   support\n\n           0     0.4194    0.1912    0.2626       272\n           1     0.7566    0.9048    0.8241       756\n\n    accuracy                         0.7160      1028\n   macro avg     0.5880    0.5480    0.5434      1028\nweighted avg     0.6674    0.7160    0.6755      1028\n\n[[ 52 220]\n [ 72 684]]\nFold 4/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5316, Accuracy: 75.94%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3471, Accuracy: 85.31%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.1391, Accuracy: 95.23%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 4 Accuracy: 0.6056\n              precision    recall  f1-score   support\n\n           0     0.3290    0.4706    0.3873       272\n           1     0.7743    0.6543    0.7093       755\n\n    accuracy                         0.6056      1027\n   macro avg     0.5517    0.5624    0.5483      1027\nweighted avg     0.6564    0.6056    0.6240      1027\n\n[[128 144]\n [261 494]]\nFold 5/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5403, Accuracy: 75.72%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3827, Accuracy: 83.58%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.1784, Accuracy: 93.97%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 5 Accuracy: 0.6670\n              precision    recall  f1-score   support\n\n           0     0.2727    0.1544    0.1972       272\n           1     0.7365    0.8517    0.7899       755\n\n    accuracy                         0.6670      1027\n   macro avg     0.5046    0.5030    0.4936      1027\nweighted avg     0.6137    0.6670    0.6329      1027\n\n[[ 42 230]\n [112 643]]\n\n✅✅✅✅✅✅✅✅✅✅✅ cait_xxs24_224.fb_dist_in1k✅✅✅✅✅✅✅✅✅✅✅✅✅\n              precision    recall  f1-score   support\n\n           0     0.3350    0.2498    0.2862      1361\n           1     0.7524    0.8213    0.7853      3777\n\n    accuracy                         0.6699      5138\n   macro avg     0.5437    0.5356    0.5358      5138\nweighted avg     0.6418    0.6699    0.6531      5138\n\n[[ 340 1021]\n [ 675 3102]]\n\n✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅\nTraining timm/crossvit_18_dagger_408.in1k...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/178M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a89ed2084534483ca1dfe0cd8596868d"}},"metadata":{}},{"name":"stdout","text":"Fold 1/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5497, Accuracy: 74.40%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.4207, Accuracy: 80.78%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.2364, Accuracy: 91.34%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 1 Accuracy: 0.7344\n              precision    recall  f1-score   support\n\n           0     0.5000    0.2784    0.3576       273\n           1     0.7751    0.8993    0.8326       755\n\n    accuracy                         0.7344      1028\n   macro avg     0.6376    0.5889    0.5951      1028\nweighted avg     0.7021    0.7344    0.7065      1028\n\n[[ 76 197]\n [ 76 679]]\nFold 2/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5290, Accuracy: 74.70%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3654, Accuracy: 84.74%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.1734, Accuracy: 94.26%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 2 Accuracy: 0.6060\n              precision    recall  f1-score   support\n\n           0     0.2805    0.3125    0.2957       272\n           1     0.7421    0.7116    0.7265       756\n\n    accuracy                         0.6060      1028\n   macro avg     0.5113    0.5121    0.5111      1028\nweighted avg     0.6199    0.6060    0.6125      1028\n\n[[ 85 187]\n [218 538]]\nFold 3/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5355, Accuracy: 75.21%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3917, Accuracy: 83.16%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.2123, Accuracy: 92.02%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 3 Accuracy: 0.6897\n              precision    recall  f1-score   support\n\n           0     0.3819    0.2794    0.3227       272\n           1     0.7636    0.8373    0.7987       756\n\n    accuracy                         0.6897      1028\n   macro avg     0.5727    0.5584    0.5607      1028\nweighted avg     0.6626    0.6897    0.6728      1028\n\n[[ 76 196]\n [123 633]]\nFold 4/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5319, Accuracy: 74.92%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3812, Accuracy: 83.26%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.1986, Accuracy: 92.85%\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Fold 4 Accuracy: 0.7098\n              precision    recall  f1-score   support\n\n           0     0.3984    0.1875    0.2550       272\n           1     0.7542    0.8980    0.8198       755\n\n    accuracy                         0.7098      1027\n   macro avg     0.5763    0.5428    0.5374      1027\nweighted avg     0.6600    0.7098    0.6702      1027\n\n[[ 51 221]\n [ 77 678]]\nFold 5/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.5401, Accuracy: 74.87%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3922, Accuracy: 83.22%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.2071, Accuracy: 92.58%\n","output_type":"stream"},{"name":"stderr","text":"                                                             ","output_type":"stream"},{"name":"stdout","text":"Fold 5 Accuracy: 0.6650\n              precision    recall  f1-score   support\n\n           0     0.3000    0.1985    0.2389       272\n           1     0.7426    0.8331    0.7853       755\n\n    accuracy                         0.6650      1027\n   macro avg     0.5213    0.5158    0.5121      1027\nweighted avg     0.6254    0.6650    0.6406      1027\n\n[[ 54 218]\n [126 629]]\n\n✅✅✅✅✅✅✅✅✅✅✅ timm/crossvit_18_dagger_408.in1k✅✅✅✅✅✅✅✅✅✅✅✅✅\n              precision    recall  f1-score   support\n\n           0     0.3555    0.2513    0.2944      1361\n           1     0.7560    0.8358    0.7939      3777\n\n    accuracy                         0.6810      5138\n   macro avg     0.5557    0.5436    0.5442      5138\nweighted avg     0.6499    0.6810    0.6616      5138\n\n[[ 342 1019]\n [ 620 3157]]\n\n✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":1}]}