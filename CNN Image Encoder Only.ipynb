{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11118864,"sourceType":"datasetVersion","datasetId":6933281}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =========================\n# IMPORTS\n# =========================\nimport os\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom torchvision.models import (\n    ResNet50_Weights,\n    MobileNet_V2_Weights,\n    MobileNet_V3_Small_Weights,\n    EfficientNet_B1_Weights,\n    Inception_V3_Weights\n)\n\n# =========================\n# SEED (FULL DETERMINISM)\n# =========================\ndef seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(42)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# =========================\n# TRANSFORM FACTORY\n# =========================\ndef get_transform(model_name):\n    if model_name == \"resnet50\":\n        return ResNet50_Weights.IMAGENET1K_V1.transforms()\n    elif model_name == \"mobilenet_v2\":\n        return MobileNet_V2_Weights.IMAGENET1K_V1.transforms()\n    elif model_name == \"mobilenet_v3_small\":\n        return MobileNet_V3_Small_Weights.IMAGENET1K_V1.transforms()\n    elif model_name == \"efficientnet_b1\":\n        return EfficientNet_B1_Weights.IMAGENET1K_V1.transforms()\n    elif model_name == \"inception_v3\":\n        return Inception_V3_Weights.IMAGENET1K_V1.transforms()  # 299x299\n    else:\n        raise ValueError(\"Unsupported model\")\n\n# =========================\n# MODEL FACTORY (CNN ONLY)\n# =========================\ndef get_model(name, num_classes):\n    if name == \"resnet50\":\n        model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n        model.fc = nn.Linear(model.fc.in_features, num_classes)\n        head_params = model.fc.parameters()\n\n    elif name == \"mobilenet_v2\":\n        model = models.mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n        head_params = model.classifier.parameters()\n\n    elif name == \"mobilenet_v3_small\":\n        model = models.mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n        head_params = model.classifier.parameters()\n\n    elif name == \"efficientnet_b1\":\n        model = models.efficientnet_b1(weights=EfficientNet_B1_Weights.IMAGENET1K_V1)\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n        head_params = model.classifier.parameters()\n\n    elif name == \"inception_v3\":\n        ##model = models.inception_v3(\n            ##weights=Inception_V3_Weights.IMAGENET1K_V1,\n            ##aux_logits=False\n        ##)\n        model = models.inception_v3(aux_logits=True)\n        model.aux_logits = False\n        model.AuxLogits = None\n        model.fc = nn.Linear(model.fc.in_features, num_classes)\n        head_params = model.fc.parameters()\n\n    else:\n        raise ValueError(\"Model not supported\")\n\n    # ğŸ”’ Freeze backbone (FAIR CNN BASELINE)\n    for p in model.parameters():\n        p.requires_grad = False\n    for p in head_params:\n        p.requires_grad = True\n\n    return model.to(device)\n\n# =========================\n# DATA PATH\n# =========================\ndata_dir = \"/kaggle/input/ekafnewsforkhawla/sorted_imagesOur\"\n\nmodels_list = [\n    \"resnet50\",\n    \"mobilenet_v2\",\n    \"mobilenet_v3_small\",\n    \"efficientnet_b1\",\n    \"inception_v3\"\n]\n\n# =========================\n# TRAIN & EVAL\n# =========================\nfor model_name in models_list:\n    print(f\"\\nğŸš€ MODEL: {model_name.upper()}\")\n\n    transform = get_transform(model_name)\n    dataset = ImageFolder(data_dir, transform=transform)\n    targets = np.array(dataset.targets)\n    class_names = dataset.classes\n\n    # ğŸ”¥ CLASS WEIGHTS (CRITICAL)\n    class_counts = np.bincount(targets)\n    class_weights = 1. / class_counts\n    weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n\n    criterion = nn.CrossEntropyLoss(weight=weights)\n\n    skf = StratifiedKFold(n_splits=5, shuffle=False, random_state=None)\n\n    all_y_true, all_y_pred = [], []\n\n    for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(targets)), targets), 1):\n        print(f\"ğŸ”¹ Fold {fold}/5\")\n\n        train_ds = Subset(dataset, train_idx)\n        val_ds   = Subset(dataset, val_idx)\n\n        train_loader = DataLoader(train_ds,batch_size=8,shuffle=True,num_workers=2,pin_memory=True)\n        val_loader = DataLoader(val_ds,batch_size=8, shuffle=False,  num_workers=2,pin_memory=True)\n        model = get_model(model_name, num_classes=len(class_names))\n        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5)\n\n        # -------- TRAIN --------\n        model.train()\n        for epoch in range(3):\n            for imgs, lbls in train_loader:\n                imgs, lbls = imgs.to(device), lbls.to(device)\n                optimizer.zero_grad()\n                outputs = model(imgs)\n                loss = criterion(outputs, lbls)\n                loss.backward()\n                optimizer.step()\n\n        # -------- VALIDATION --------\n        model.eval()\n        with torch.no_grad():\n            for imgs, lbls in val_loader:\n                imgs = imgs.to(device)\n                outputs = model(imgs)\n                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n                all_y_pred.extend(preds)\n                all_y_true.extend(lbls.numpy())\n\n    print(\"âœ…\" * 60)\n    print(f\"FINAL RESULTS â€” {model_name.upper()}\")\n    print(classification_report(all_y_true, all_y_pred, target_names=class_names, digits=4))\n    print(confusion_matrix(all_y_true, all_y_pred))\n    print(\"ğŸ”¥\" * 60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:02:23.677948Z","iopub.execute_input":"2026-02-02T15:02:23.678640Z","iopub.status.idle":"2026-02-02T15:42:39.152731Z","shell.execute_reply.started":"2026-02-02T15:02:23.678603Z","shell.execute_reply":"2026-02-02T15:42:39.151780Z"}},"outputs":[{"name":"stdout","text":"\nğŸš€ MODEL: RESNET50\nğŸ”¹ Fold 1/5\nğŸ”¹ Fold 2/5\nğŸ”¹ Fold 3/5\nğŸ”¹ Fold 4/5\nğŸ”¹ Fold 5/5\nâœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…\nFINAL RESULTS â€” RESNET50\n              precision    recall  f1-score   support\n\n        Fake     0.2670    0.3600    0.3066      1361\n        Real     0.7363    0.6439    0.6870      3777\n\n    accuracy                         0.5687      5138\n   macro avg     0.5017    0.5020    0.4968      5138\nweighted avg     0.6120    0.5687    0.5862      5138\n\n[[ 490  871]\n [1345 2432]]\nğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\n\nğŸš€ MODEL: MOBILENET_V2\nğŸ”¹ Fold 1/5\nğŸ”¹ Fold 2/5\nğŸ”¹ Fold 3/5\nğŸ”¹ Fold 4/5\nğŸ”¹ Fold 5/5\nâœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…\nFINAL RESULTS â€” MOBILENET_V2\n              precision    recall  f1-score   support\n\n        Fake     0.2630    0.3012    0.2808      1361\n        Real     0.7343    0.6958    0.7145      3777\n\n    accuracy                         0.5913      5138\n   macro avg     0.4986    0.4985    0.4977      5138\nweighted avg     0.6094    0.5913    0.5996      5138\n\n[[ 410  951]\n [1149 2628]]\nğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\n\nğŸš€ MODEL: MOBILENET_V3_SMALL\nğŸ”¹ Fold 1/5\nğŸ”¹ Fold 2/5\nğŸ”¹ Fold 3/5\nğŸ”¹ Fold 4/5\nğŸ”¹ Fold 5/5\nâœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…\nFINAL RESULTS â€” MOBILENET_V3_SMALL\n              precision    recall  f1-score   support\n\n        Fake     0.2961    0.4071    0.3428      1361\n        Real     0.7530    0.6513    0.6985      3777\n\n    accuracy                         0.5866      5138\n   macro avg     0.5245    0.5292    0.5206      5138\nweighted avg     0.6320    0.5866    0.6043      5138\n\n[[ 554  807]\n [1317 2460]]\nğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\n\nğŸš€ MODEL: EFFICIENTNET_B1\nğŸ”¹ Fold 1/5\nğŸ”¹ Fold 2/5\nğŸ”¹ Fold 3/5\nğŸ”¹ Fold 4/5\nğŸ”¹ Fold 5/5\nâœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…\nFINAL RESULTS â€” EFFICIENTNET_B1\n              precision    recall  f1-score   support\n\n        Fake     0.2900    0.4247    0.3447      1361\n        Real     0.7510    0.6254    0.6825      3777\n\n    accuracy                         0.5722      5138\n   macro avg     0.5205    0.5250    0.5136      5138\nweighted avg     0.6289    0.5722    0.5930      5138\n\n[[ 578  783]\n [1415 2362]]\nğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\n\nğŸš€ MODEL: INCEPTION_V3\nğŸ”¹ Fold 1/5\nğŸ”¹ Fold 2/5\nğŸ”¹ Fold 3/5\nğŸ”¹ Fold 4/5\nğŸ”¹ Fold 5/5\nâœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…\nFINAL RESULTS â€” INCEPTION_V3\n              precision    recall  f1-score   support\n\n        Fake     0.2554    0.2351    0.2448      1361\n        Real     0.7320    0.7530    0.7424      3777\n\n    accuracy                         0.6158      5138\n   macro avg     0.4937    0.4940    0.4936      5138\nweighted avg     0.6058    0.6158    0.6106      5138\n\n[[ 320 1041]\n [ 933 2844]]\nğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\n","output_type":"stream"}],"execution_count":6}]}